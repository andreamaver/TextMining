{"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Package for Classification\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import (precision_recall_curve, auc, confusion_matrix,\n","                             f1_score, fbeta_score, precision_score,\n","                             recall_score, classification_report)\n","from sklearn.svm import LinearSVC\n","from numpy import array\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.feature_selection import SelectPercentile as SP\n","\n","# For SVD\n","from scipy.linalg import svd\n","from sklearn.decomposition import TruncatedSVD\n","\n","# For Cross-Validation\n","from sklearn.model_selection import StratifiedKFold\n","\n","# For Doc2Vec\n","import gensim\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from nltk.tokenize import word_tokenize\n","from gensim.models.doc2vec import Doc2Vec\n","import nltk\n","nltk.download('punkt')\n","\n","# For load data\n","from google.colab import drive\n","from shutil import copyfile\n","from shutil import copytree\n","\n","# Set Random Seed\n","import random\n","random.seed(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CEvz84_MXoKh","executionInfo":{"status":"ok","timestamp":1641984578970,"user_tz":-60,"elapsed":3872,"user":{"displayName":"Marco Braga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00946921907810722360"}},"outputId":"7c89187a-a14e-4fdb-b58c-e7446e4c84a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":101636,"status":"ok","timestamp":1641984747540,"user":{"displayName":"Marco Braga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00946921907810722360"},"user_tz":-60},"id":"-5rW3dDzvWoB","outputId":"d85311f8-f3b7-43a7-cca6-7f9e1de8cc02"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'data_preprocessed_stopwords_class.csv'"]},"metadata":{},"execution_count":4}],"source":["# Link Google Drive account\n","drive.mount('/content/gdrive')\n","\n","copyfile('gdrive/My Drive/Progetto_TMeS/data_preprocessed_stopwords_class.csv', 'data_preprocessed_stopwords_class.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLo87Wyyxjm8"},"outputs":[],"source":["# Load Data\n","data=pd.read_csv('data_preprocessed_stopwords_class.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NeRcx8qkxvO5"},"outputs":[],"source":["# For Topic Classification we need only Token Words and Labels\n","data=data[['stem_token_space','lemm','topic']]"]},{"cell_type":"code","source":["# Define function for vanilla accuracy\n","def results(y_test,y_pred):\n","  # RESULTS\n","  matrix = confusion_matrix(y_test, y_pred)\n","  # Vanilla Accuracy: sum of elements on diagonal/all elements\n","  return matrix.diagonal().sum()/matrix.sum()\n"],"metadata":{"id":"Kw2wiiN-tfgn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Doc2Vec"],"metadata":{"id":"loTPEnbUt2Nd"}},{"cell_type":"code","source":["y=data.topic.values"],"metadata":{"id":"qYiMbYCm_0sk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lemmatization\n","X = data.lemm.values\n","# Split Train and Test, Test is 20% of original Data \n","X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.20, random_state=10)"],"metadata":{"id":"ht6WQZPlFoEt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tags_index = {'a': 1 , 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g':7, 'h':8}"],"metadata":{"id":"GojmQQiAG05E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_documents = [TaggedDocument(words=_d.split(), tags=[tags_index.get(y_train[i], 8)]) for i, _d in enumerate(X_train)]\n","test_documents = [TaggedDocument(words=_d.split(), tags=[tags_index.get(y_test[i], 8)]) for i, _d in enumerate(X_test)]"],"metadata":{"id":"Q-2iCBsPVJO-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Doc2Vec\n","# Create Vocabolary and define model\n","model = gensim.models.doc2vec.Doc2Vec(dm=1,vector_size=350, min_count=1, epochs=30)\n","from tqdm import tqdm\n","model.build_vocab(([x for x in tqdm(train_documents)]))\n"],"metadata":{"id":"R3ohlorit1n_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641839447036,"user_tz":-60,"elapsed":55223,"user":{"displayName":"Marco Braga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02525899923469906841"}},"outputId":"68469246-bccd-4615-b2e9-a9271f1e1660"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 36021/36021 [00:00<00:00, 2047056.76it/s]\n"]}]},{"cell_type":"code","source":["# Train model\n","model.train(train_documents,total_examples=len(train_documents), epochs=30)"],"metadata":{"id":"_xOawj24VbVl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function for apply Doc2Vec to train and test set\n","def vector_for_learning(model, input_docs):\n","    sents = input_docs\n","    targets, feature_vectors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n","    return targets, feature_vectors"],"metadata":{"id":"wCeMYrw-WMiQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply Doc2Vec\n","y_train, X_train_d2v = vector_for_learning(model, train_documents)\n","y_test, X_test_d2v = vector_for_learning(model, test_documents)\n"],"metadata":{"id":"EopZMT7zNh4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classification with random Forest\n","clf = RandomForestClassifier()\n","clf.fit(X_train_d2v, y_train)\n","y_pred = clf.predict(X_test_d2v)\n","# Obtain confusion Matrix\n","matrix=confusion_matrix(y_test, y_pred)\n","matrix"],"metadata":{"id":"lpcQnHpxdB1e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641850848655,"user_tz":-60,"elapsed":82846,"user":{"displayName":"Marco Braga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02525899923469906841"}},"outputId":"74f24721-35ff-4719-fb2d-556b85962063"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 227,   71,   23,   67,  169,   81,   97,   45],\n","       [  22,  202,    7,  133,  331,  243,  168,   79],\n","       [  40,   47,  135,   64,   28,   60,   72,   22],\n","       [  16,   81,    4,  732,  126,  109,   57,   30],\n","       [  22,   88,    0,   55, 1016,  136,   88,   38],\n","       [  21,   99,    0,   71,  282,  635,  114,   89],\n","       [  15,   53,    4,   44,  114,   92,  816,  270],\n","       [  12,   45,    1,   25,   75,  106,  383,  609]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Vanilla Accuracy for Doc2Vec\n","results(y_test, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18GDUhGKUZTi","executionInfo":{"status":"ok","timestamp":1641850849380,"user_tz":-60,"elapsed":3,"user":{"displayName":"Marco Braga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02525899923469906841"}},"outputId":"d7b3e222-f50d-4a6b-e663-9bc70443c40d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.48545414168332224"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"JYBC1lSoF1jc"},"source":["#Classification"]},{"cell_type":"markdown","source":["## With Lemmatization"],"metadata":{"id":"0PP4aC7N3l9b"}},{"cell_type":"code","source":["ds=data[['lemm','topic']]\n","y=ds.topic.values"],"metadata":{"id":"PUxo4c9MBV6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lemmatization\n","XX_l=ds.lemm.values\n","# Dictionary for results\n","result_lemma={}\n","\n","result_dt={}\n","result_rf={}\n","result_knn={}\n","result_svm={}\n","\n","X_data, X_test, y_data, y_test=train_test_split(XX_l, y, test_size=0.20, random_state=20)\n","\n","X = X_data\n","# Label \n","y = y_data\n","\n","# Different N-grams\n","n_grams=[(1,1),(1,2),(2,2)]\n","\n","for n_gram in n_grams:\n","  \n","  # Different number of features\n","  for maxf in [1000,5000,15000]:\n","\n","    # Tf-Idf Representation with \"i-grams\" (1-grams and 2-grams)\n","    tfidf_vect = TfidfVectorizer(min_df=2, max_df=0.4, max_features=maxf, ngram_range=n_gram)\n","    \n","    # Cross Validation (k=3)\n","    skf = StratifiedKFold(n_splits=3)\n","\n","    k=0\n","\n","    for train_index, val_index in skf.split(X, y):\n","      \n","      X_train, X_val = X[train_index], X[val_index]\n","      y_train, y_val = y[train_index], y[val_index]\n","      \n","      # Fit Tf-Idf on Train set\n","      X_train_transformed = tfidf_vect.fit_transform(X_train)\n","\n","      # Apply Tf-Idf model on Test\n","      X_val_transformed = tfidf_vect.transform(X_val)\n","\n","      # DECISION TREE\n","      clf = DecisionTreeClassifier().fit(X_train_transformed, y_train)\n","      y_pred = clf.predict(X_val_transformed)\n","      \n","      # RESULTS\n","      result_dt[(k,n_gram,maxf)]=results(y_val,y_pred)\n","\n","      # RANDOM FOREST\n","      clf = RandomForestClassifier().fit(X_train_transformed, y_train)\n","      y_pred = clf.predict(X_val_transformed)\n","      \n","      # RESULTS\n","      \n","      result_rf[(k,n_gram,maxf)]=results(y_val,y_pred)\n","      \n","      # KNN\n","\n","      clf = KNeighborsClassifier(n_neighbors=100).fit(X_train_transformed, y_train)\n","      y_pred = clf.predict(X_val_transformed)\n","\n","      # RESULTS\n","      \n","      result_knn[(k,n_gram,maxf)]=results(y_val,y_pred)\n","\n","      #SVM\n","\n","      # Reduce dimension with SVD for SVM (150 for high computational cost)\n","      svd = TruncatedSVD(n_components=150,random_state=20)\n","      svd.fit(X_train_transformed)\n","      X_train_svd= svd.transform(X_train_transformed)\n","\n","      # Fit SVD for Test set\n","      svd.fit(X_val_transformed)\n","      X_val_svd= svd.transform(X_val_transformed)\n","\n","      # Train SVM\n","      clf = LinearSVC()\n","      clf.fit(X_train_svd, y_train)\n","\n","      y_pred = clf.predict(X_val_svd)\n","\n","      # RESULTS\n","      result_svm[(k,n_gram,maxf)]=results(y_val,y_pred)\n","      \n","      k=k+1\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ENYMSSkilEQH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_lemma={'DT':result_dt,'RF':result_rf,'SVM':result_svm,'KNN':result_knn}\n","risultati"],"metadata":{"id":"GWGfGIfnOUMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["risultati['lemmatization']={}\n","for n_gram in n_grams:\n","\n","  for maxf in [1000,5000,15000]:\n","    for tecnica in ['DT','RF','SVM','KNN']:\n","      # Obtain mean vanialla accuracy after Cross Validation\n","      risultati['lemmatization'][(tecnica,n_gram,maxf)]=round((result_lemma[tecnica][(0,n_gram,maxf)]+\n","                      result_lemma[tecnica][(1,n_gram,maxf)]+result_lemma[tecnica][(2,n_gram,maxf)])/3,3)"],"metadata":{"id":"VL9MuQqC2fk6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## With Stemming"],"metadata":{"id":"qLfDExVc3qSa"}},{"cell_type":"code","source":["# Stemming\n","ds=data[['stem_token_space','topic']]\n","y=ds.topic.values\n","XX_s=ds.stem_token_space.values\n","\n","# Dictionary for results\n","result_stemm={}\n","\n","result_dt={}\n","result_rf={}\n","result_knn={}\n","result_svm={}\n","\n","X_data, X_test, y_data, y_test=train_test_split(XX_s, y, test_size=0.20, random_state=20)\n","\n","X = X_data\n","# Label \n","y = y_data\n","\n","# Different n-grams that give better results with lemmatization\n","n_grams=[(1,1),(1,2)]\n","\n","for n_gram in n_grams:\n","\n","  # Select number of features that maximize accuracy with lemmatization\n","  for maxf in [15000]:\n","\n","    # Tf-Idf Representation with \"i-grams\" (1-grams and 2-grams)\n","    tfidf_vect = TfidfVectorizer(min_df=2, max_df=0.4, max_features=maxf, ngram_range=n_gram)\n","    \n","    # Cross Validation (k=3)\n","    skf = StratifiedKFold(n_splits=3)\n","\n","    k=0\n","\n","    for train_index, val_index in skf.split(X, y):\n","      \n","      X_train, X_val = X[train_index], X[val_index]\n","      y_train, y_val = y[train_index], y[val_index]\n","      \n","      # Fit Tf-Idf on Train set\n","      X_train_transformed = tfidf_vect.fit_transform(X_train)\n","\n","      # Apply Tf-Idf model on Test\n","      X_val_transformed = tfidf_vect.transform(X_val)\n","\n","      # DECISION TREE\n","      clf = DecisionTreeClassifier().fit(X_train_transformed, y_train)\n","      y_pred = clf.predict(X_val_transformed)\n","      \n","      # RESULTS\n","      result_dt[(k,n_gram,maxf)]=results(y_val,y_pred)\n","\n","      # RANDOM FOREST\n","      clf = RandomForestClassifier().fit(X_train_transformed, y_train)\n","      y_pred = clf.predict(X_val_transformed)\n","      \n","      # RESULTS\n","      \n","      result_rf[(k,n_gram,maxf)]=results(y_val,y_pred)\n","      \n","      # KNN\n","\n","      clf = KNeighborsClassifier(n_neighbors=100).fit(X_train_transformed, y_train)\n","      y_pred = clf.predict(X_val_transformed)\n","\n","      # RESULTS\n","      \n","      result_knn[(k,n_gram,maxf)]=results(y_val,y_pred)\n","\n","      #SVM\n","\n","      # Reduce dimension with SVD for SVM (150 for high computational cost)\n","      svd = TruncatedSVD(n_components=150,random_state=20)\n","      svd.fit(X_train_transformed)\n","      X_train_svd= svd.transform(X_train_transformed)\n","\n","      # Fit SVD for Test set\n","      svd.fit(X_val_transformed)\n","      X_val_svd= svd.transform(X_val_transformed)\n","\n","      # Train SVM\n","      clf = LinearSVC()\n","      clf.fit(X_train_svd, y_train)\n","\n","      y_pred = clf.predict(X_val_svd)\n","\n","      # RESULTS\n","      result_svm[(k,n_gram,maxf)]=results(y_val,y_pred)\n","      \n","      k=k+1\n"],"metadata":{"id":"mBl4MrOY2tJx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_stemm={'DT':result_dt,'RF':result_rf,'SVM':result_svm,'KNN':result_knn}"],"metadata":{"id":"qYWmpR0G4H_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["risultati['stemm']={}\n","for n_gram in n_grams:\n","  maxf=15000\n","  for tecnica in ['DT','RF','SVM','KNN']:\n","    # Mean of Vanilla Accuracy\n","    risultati['stemm'][(tecnica,n_gram,maxf)]=round((result_stemm[tecnica][(0,n_gram,maxf)]+\n","                      result_stemm[tecnica][(1,n_gram,maxf)]+result_stemm[tecnica][(2,n_gram,maxf)])/3,3)"],"metadata":{"id":"wHBv7rdp2wRp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Final Test\n"],"metadata":{"id":"PoKOMH_26Zv0"}},{"cell_type":"code","source":["# Apply the best model to Test Set\n","ds=data[['lemm','topic']]\n","y=ds.topic.values\n","XX_l=ds.lemm.values\n","\n","X_data, X_test, y_data, y_test=train_test_split(XX_l, y, test_size=0.20, random_state=20)\n","\n","X = X_data\n","# Label \n","y = y_data\n","\n","# Tf-Idf Representation with 1-grams and 2-grams and 15000 max_features\n","tfidf_vect = TfidfVectorizer(min_df=2, max_df=0.4, max_features=15000, ngram_range=(1,2))\n","    \n","# Fit Tf-Idf on Train set\n","X_train_transformed = tfidf_vect.fit_transform(X_data)\n","\n","# Apply Tf-Idf model on Test\n","X_test_transformed = tfidf_vect.transform(X_test)\n","\n","# The best model is RANDOM FOREST\n","clf = RandomForestClassifier().fit(X_train_transformed, y_data)\n","y_pred = clf.predict(X_test_transformed)\n","      \n","# RESULTS (Final Vanilla Accuracy)\n","print(results(y_test,y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJKkRaogrfK5","executionInfo":{"status":"ok","timestamp":1641985347837,"user_tz":-60,"elapsed":534679,"user":{"displayName":"Marco Braga","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00946921907810722360"}},"outputId":"3715b707-a7a2-4bbc-d20c-873dd68e0654"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6547856984232734\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"3.Topic_Class.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}